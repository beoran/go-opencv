/*
Go Language wrappers around Open CV
*/
package opencv

// #include <opencv/cv.h>
// #include <opencv/cvaux.h>
// #include <opencv/highgui.h>
import "C"
import "unsafe" 
import "fmt"
import "os"


// Opencv's many, many numerical constants
// Generated by cleaning up the results of 
// egrep '#define[ ]+[A-Z0-9_]+[ ]+[0-9x]+'  /usr/local/include/opencv/*.h |  
// awk 'BEGIN{FS="[ ]+" ; SPACES="                                "} 
// sp = substr(SPACES,0,32-length($2)) ; name=gensub("CV_","","1",$2); 
// print(name "" sp "= " $3); }'
const (
  BLUR_NO_SCALE                = 0
  BLUR                         = 1
  GAUSSIAN                     = 2
  MEDIAN                       = 3
  BILATERAL                    = 4
  INPAINT_NS                   = 0
  INPAINT_TELEA                = 1
  MAX_SOBEL_KSIZE              = 7
  BGR2BGRA                     = 0
  BGRA2BGR                     = 1
  BGR2RGBA                     = 2
  RGBA2BGR                     = 3
  BGR2RGB                      = 4
  BGRA2RGBA                    = 5
  BGR2GRAY                     = 6
  RGB2GRAY                     = 7
  GRAY2BGR                     = 8
  GRAY2BGRA                    = 9
  BGRA2GRAY                    = 10
  RGBA2GRAY                    = 11
  BGR2BGR565                   = 12
  RGB2BGR565                   = 13
  BGR5652BGR                   = 14
  BGR5652RGB                   = 15
  BGRA2BGR565                  = 16
  RGBA2BGR565                  = 17
  BGR5652BGRA                  = 18
  BGR5652RGBA                  = 19
  GRAY2BGR565                  = 20
  BGR5652GRAY                  = 21
  BGR2BGR555                   = 22
  RGB2BGR555                   = 23
  BGR5552BGR                   = 24
  BGR5552RGB                   = 25
  BGRA2BGR555                  = 26
  RGBA2BGR555                  = 27
  BGR5552BGRA                  = 28
  BGR5552RGBA                  = 29
  GRAY2BGR555                  = 30
  BGR5552GRAY                  = 31
  BGR2XYZ                      = 32
  RGB2XYZ                      = 33
  XYZ2BGR                      = 34
  XYZ2RGB                      = 35
  BGR2HSV                      = 40
  RGB2HSV                      = 41
  BGR2HLS                      = 52
  RGB2HLS                      = 53
  HSV2BGR                      = 54
  HSV2RGB                      = 55
  HLS2BGR                      = 60
  HLS2RGB                      = 61
  COLORCVT_MAX                 = 100
  INTER_NN                     = 0
  INTER_LINEAR                 = 1
  INTER_CUBIC                  = 2
  INTER_AREA                   = 3
  WARP_FILL_OUTLIERS           = 8
  WARP_INVERSE_MAP             = 16
  SHAPE_RECT                   = 0
  SHAPE_CROSS                  = 1
  SHAPE_ELLIPSE                = 2
  SHAPE_CUSTOM                 = 100
  MOP_OPEN                     = 2
  MOP_CLOSE                    = 3
  MOP_GRADIENT                 = 4
  MOP_TOPHAT                   = 5
  MOP_BLACKHAT                 = 6
  TM_SQDIFF                    = 0
  TM_SQDIFF_NORMED             = 1
  TM_CCORR                     = 2
  TM_CCORR_NORMED              = 3
  TM_CCOEFF                    = 4
  TM_CCOEFF_NORMED             = 5
  LKFLOW_PYR_A_READY           = 1
  LKFLOW_PYR_B_READY           = 2
  LKFLOW_INITIAL_GUESSES       = 4
  LKFLOW_GET_MIN_EIGENVALS     = 8
  POLY_APPROX_DP               = 0
  DOMINANT_IPAN                = 1
  CONTOURS_MATCH_I1            = 1
  CONTOURS_MATCH_I2            = 2
  CONTOURS_MATCH_I3            = 3
  CONTOUR_TREES_MATCH_I1       = 1
  CLOCKWISE                    = 1
  COUNTER_CLOCKWISE            = 2
  COMP_CORREL                  = 0
  COMP_CHISQR                  = 1
  COMP_INTERSECT               = 2
  COMP_BHATTACHARYYA           = 3
  VALUE                        = 1
  ARRAY                        = 2
  DIST_MASK_3                  = 3
  DIST_MASK_5                  = 5
  DIST_MASK_PRECISE            = 0
  THRESH_BINARY                = 0
  THRESH_BINARY_INV            = 1
  THRESH_TRUNC                 = 2
  THRESH_TOZERO                = 3
  THRESH_TOZERO_INV            = 4
  THRESH_MASK                  = 7
  THRESH_OTSU                  = 8
  ADAPTIVE_THRESH_MEAN_C       = 0
  ADAPTIVE_THRESH_GAUSSIAN_C   = 1
  HOUGH_STANDARD               = 0
  HOUGH_PROBABILISTIC          = 1
  HOUGH_MULTI_SCALE            = 2
  HOUGH_GRADIENT               = 3
  HAAR_DO_CANNY_PRUNING        = 1
  HAAR_SCALE_IMAGE             = 2
  HAAR_FIND_BIGGEST_OBJECT     = 4
  HAAR_DO_ROUGH_SEARCH         = 8
  LMEDS                        = 4
  RANSAC                       = 8
  CALIB_CB_ADAPTIVE_THRESH     = 1
  CALIB_CB_NORMALIZE_IMAGE     = 2
  CALIB_CB_FILTER_QUADS        = 4
  CALIB_USE_INTRINSIC_GUESS    = 1
  CALIB_FIX_ASPECT_RATIO       = 2
  CALIB_FIX_PRINCIPAL_POINT    = 4
  CALIB_ZERO_TANGENT_DIST      = 8
  CALIB_FIX_FOCAL_LENGTH       = 16
  CALIB_FIX_K1                 = 32
  CALIB_FIX_K2                 = 64
  CALIB_FIX_K3                 = 128
  CALIB_FIX_INTRINSIC          = 256
  CALIB_SAME_FOCAL_LENGTH      = 512
  CALIB_ZERO_DISPARITY         = 1024
  FM_7POINT                    = 1
  FM_8POINT                    = 2
  STEREO_BM_NORMALIZED_RESPONSE= 0
  STEREO_BM_BASIC              = 0
  STEREO_BM_FISH_EYE           = 1
  STEREO_BM_NARROW             = 2
  EIGOBJ_NO_CALLBACK           = 0
  EIGOBJ_INPUT_CALLBACK        = 1
  EIGOBJ_OUTPUT_CALLBACK       = 2
  EIGOBJ_BOTH_CALLBACK         = 3
  CLIQUE_TIME_OFF              = 2
  CLIQUE_FOUND                 = 1
  CLIQUE_END                   = 0
  UNDEF_SC_PARAM               = 12345
  IDP_BIRCHFIELD_PARAM1        = 25
  IDP_BIRCHFIELD_PARAM2        = 5
  IDP_BIRCHFIELD_PARAM3        = 12
  IDP_BIRCHFIELD_PARAM4        = 15
  IDP_BIRCHFIELD_PARAM5        = 25
  DISPARITY_BIRCHFIELD         = 0
  CAMERA_TO_WARP               = 1
  WARP_TO_CAMERA               = 2
  GLCM_OPTIMIZATION_HISTOGRAM  = 0
  GLCMDESC_OPTIMIZATION_ALLOWDOUBLENEST= 10
  GLCMDESC_OPTIMIZATION_ALLOWTRIPLENEST= 11
  GLCMDESC_OPTIMIZATION_HISTOGRAM= 4
  GLCMDESC_ENTROPY             = 0
  GLCMDESC_ENERGY              = 1
  GLCMDESC_HOMOGENITY          = 2
  GLCMDESC_CONTRAST            = 3
  GLCMDESC_CLUSTERTENDENCY     = 4
  GLCMDESC_CLUSTERSHADE        = 5
  GLCMDESC_CORRELATION         = 6
  GLCMDESC_CORRELATIONINFO1    = 7
  GLCMDESC_CORRELATIONINFO2    = 8
  GLCMDESC_MAXIMUMPROBABILITY  = 9
  GLCM_ALL                     = 0
  GLCM_GLCM                    = 1
  GLCM_DESC                    = 2
  NUM_FACE_ELEMENTS            = 3
  BGFG_FGD_LC                  = 128
  BGFG_FGD_N1C                 = 15
  BGFG_FGD_N2C                 = 25
  BGFG_FGD_LCC                 = 64
  BGFG_FGD_N1CC                = 25
  BGFG_FGD_N2CC                = 40
  BGFG_FGD_ALPHA_1             = 0.1
  BGFG_FGD_ALPHA_2             = 0.005
  BGFG_FGD_ALPHA_3             = 0.1
  BGFG_FGD_DELTA               = 2
  BGFG_FGD_T                   = 0.9
  BGFG_FGD_MINAREA             = 15.
  BGFG_FGD_BG_UPDATE_TRESH     = 0.5
  BGFG_MOG_MAX_NGAUSSIANS      = 500
  BGFG_MOG_BACKGROUND_THRESHOLD= 0.7
  BGFG_MOG_STD_THRESHOLD       = 2.5
  BGFG_MOG_WINDOW_SIZE         = 200
  BGFG_MOG_NGAUSSIANS          = 5
  BGFG_MOG_WEIGHT_INIT         = 0.05
  BGFG_MOG_SIGMA_INIT          = 30
  BGFG_MOG_MINAREA             = 15.0
  BGFG_MOG_NCOLORS             = 3
  RODRIGUES_M2V                = 0
  RODRIGUES_V2M                = 1
  SHIFT_NONE                   = 2
  SHIFT_LEFT                   = 1
  SHIFT_RIGHT                  = 3
  SHIFT_UP                     = 6
  SHIFT_DOWN                   = 10
  SHIFT_LU                     = 5
  SHIFT_RU                     = 7
  SHIFT_LD                     = 9
  SHIFT_RD                     = 11
  RANDOM_INVERT                = 0x7FFFFFFF
  RETR_EXTERNAL                = 0
  RETR_LIST                    = 1
  RETR_CCOMP                   = 2
  RETR_TREE                    = 3
  CHAIN_CODE                   = 0
  CHAIN_APPROX_NONE            = 1
  CHAIN_APPROX_SIMPLE          = 2
  CHAIN_APPROX_TC89_L1         = 3
  CHAIN_APPROX_TC89_KCOS       = 4
  LINK_RUNS                    = 5
  DIST_L1                      = 1
  DIST_L2                      = 2
  DIST_C                       = 3
  DIST_L12                     = 4
  DIST_FAIR                    = 5
  DIST_WELSCH                  = 6
  DIST_HUBER                   = 7
  HAAR_MAGIC_VAL               = 0x42500000
  HAAR_FEATURE_MAX             = 3
  MAJOR_VERSION                = 2
  MINOR_VERSION                = 0
  SUBMINOR_VERSION             = 0
  AUTOSTEP                     = 0x7fffffff
  MAX_ARR                      = 10
  NO_DEPTH_CHECK               = 1
  NO_CN_CHECK                  = 2
  NO_SIZE_CHECK                = 4
  CMP_EQ                       = 0
  CMP_GT                       = 1
  CMP_GE                       = 2
  CMP_LT                       = 3
  CMP_LE                       = 4
  CMP_NE                       = 5
  CHECK_RANGE                  = 1
  CHECK_QUIET                  = 2
  RAND_UNI                     = 0
  RAND_NORMAL                  = 1
  SORT_EVERY_ROW               = 0
  SORT_EVERY_COLUMN            = 1
  SORT_ASCENDING               = 0
  SORT_DESCENDING              = 16
  GEMM_A_T                     = 1
  GEMM_B_T                     = 2
  GEMM_C_T                     = 4
  SVD_MODIFY_A                 = 1
  SVD_U_T                      = 2
  SVD_V_T                      = 4
  LU                           = 0
  SVD                          = 1
  SVD_SYM                      = 2
  CHOLESKY                     = 3
  QR                           = 4
  NORMAL                       = 16
  COVAR_SCRAMBLED              = 0
  COVAR_NORMAL                 = 1
  COVAR_USE_AVG                = 2
  COVAR_SCALE                  = 4
  COVAR_ROWS                   = 8
  COVAR_COLS                   = 16
  PCA_DATA_AS_ROW              = 0
  PCA_DATA_AS_COL              = 1
  PCA_USE_AVG                  = 2
  CV_C                         = 1
  L1                           = 2
  L2                           = 4
  NORM_MASK                    = 7
  RELATIVE                     = 8
  DIFF                         = 16
  MINMAX                       = 32
  REDUCE_SUM                   = 0
  REDUCE_AVG                   = 1
  REDUCE_MAX                   = 2
  REDUCE_MIN                   = 3
  DXT_FORWARD                  = 0
  DXT_INVERSE                  = 1
  DXT_SCALE                    = 2
  DXT_ROWS                     = 4
  DXT_MUL_CONJ                 = 8
  FRONT                        = 1
  BACK                         = 0
  GRAPH_VERTEX                 = 1
  GRAPH_TREE_EDGE              = 2
  GRAPH_BACK_EDGE              = 4
  GRAPH_FORWARD_EDGE           = 8
  GRAPH_CROSS_EDGE             = 16
  GRAPH_ANY_EDGE               = 30
  GRAPH_NEW_TREE               = 32
  GRAPH_BACKTRACKING           = 64
  AA                           = 16
  FONT_HERSHEY_SIMPLEX         = 0
  FONT_HERSHEY_PLAIN           = 1
  FONT_HERSHEY_DUPLEX          = 2
  FONT_HERSHEY_COMPLEX         = 3
  FONT_HERSHEY_TRIPLEX         = 4
  FONT_HERSHEY_COMPLEX_SMALL   = 5
  FONT_HERSHEY_SCRIPT_SIMPLEX  = 6
  FONT_HERSHEY_SCRIPT_COMPLEX  = 7
  FONT_ITALIC                  = 16
  KMEANS_USE_INITIAL_LABELS    = 1
  MAX_INLINE_MAT_OP_SIZE       = 10
  MAX_LOCAL_MAT_SIZE           = 32
  DEFAULT_IMAGE_ROW_ALIGN      = 4
  DEFAULT_MAT_ROW_ALIGN        = 1
  MALLOC_ALIGN                 = 16
  SPARSE_HASH_RATIO            = 3
  MAX_STRLEN                   = 1024
  MAX_THREADS                  = 128
  ORIGIN_TL                    = 0
  ORIGIN_BL                    = 1
  POS_INF                      = 0x7f800000
  NEG_INF                      = 0x807fffff
  CV_1F                        = 0x3f800000
  PI                           = 3.1415926535897932384626433832795
  LOG2                         = 0.69314718055994530941723212145818
  IPL_DEPTH_SIGN               = 0x80000000
  IPL_DEPTH_1U                 = 1
  IPL_DEPTH_8U                    = 8
  IPL_DEPTH_16U                   = 16
  IPL_DEPTH_32F                   = 32
  IPL_DATA_ORDER_PIXEL            = 0
  IPL_DATA_ORDER_PLANE            = 1
  IPL_ORIGIN_TL                   = 0
  IPL_ORIGIN_BL                   = 1
  IPL_ALIGN_4BYTES                = 4
  IPL_ALIGN_8BYTES                = 8
  IPL_ALIGN_16BYTES               = 16
  IPL_ALIGN_32BYTES               = 32
  IPL_BORDER_CONSTANT             = 0
  IPL_BORDER_REPLICATE            = 1
  IPL_BORDER_REFLECT              = 2
  IPL_BORDER_WRAP                 = 3
  IPL_IMAGE_HEADER                = 1
  IPL_IMAGE_DATA                  = 2
  IPL_IMAGE_ROI                   = 4
  IPL_BORDER_REFLECT_101          = 4
  IPL_DEPTH_64F                   = 64
  CN_MAX                       = 64
  CN_SHIFT                     = 3
  CV_8U                        = 0
  CV_8S                        = 1
  CV_16U                       = 2
  CV_16S                       = 3
  CV_32S                       = 4
  CV_32F                       = 5
  CV_64F                       = 6
  USRTYPE1                     = 7
  AUTO_STEP                    = 0x7fffffff
  MAT_CONT_FLAG_SHIFT          = 14
  MAT_TEMP_FLAG_SHIFT          = 15
  MAGIC_MASK                   = 0xFFFF0000
  MAT_MAGIC_VAL                = 0x42420000
  MATND_MAGIC_VAL              = 0x42430000
  MAX_DIM                      = 32
  SPARSE_MAT_MAGIC_VAL         = 0x42440000
  HIST_MAGIC_VAL               = 0x42450000
  HIST_ARRAY                   = 0
  HIST_SPARSE                  = 1
  HIST_UNIFORM                 = 1
  TERMCRIT_ITER                = 1
  TERMCRIT_EPS                 = 2
  WHOLE_SEQ_END_INDEX          = 0x3fffffff
  STORAGE_MAGIC_VAL            = 0x42890000
  SEQ_MAGIC_VAL                = 0x42990000
  SET_MAGIC_VAL                = 0x42980000
  SEQ_ELTYPE_BITS              = 9
  SEQ_ELTYPE_GENERIC           = 0
  SEQ_ELTYPE_GRAPH_EDGE        = 0
  SEQ_ELTYPE_GRAPH_VERTEX      = 0
  SEQ_ELTYPE_TRIAN_ATR         = 0
  SEQ_ELTYPE_CONNECTED_COMP    = 0
  SEQ_KIND_BITS                = 3
  STORAGE_READ                 = 0
  STORAGE_WRITE                = 1
  STORAGE_APPEND               = 2
  NODE_NONE                    = 0
  NODE_INT                     = 1
  NODE_REAL                    = 2
  NODE_STR                     = 3
  NODE_REF                     = 4
  NODE_SEQ                     = 5
  NODE_MAP                     = 6
  NODE_TYPE_MASK               = 7
  NODE_FLOW                    = 8
  NODE_USER                    = 16
  NODE_EMPTY                   = 32
  NODE_NAMED                   = 64
  NODE_SEQ_SIMPLE              = 256
  WINDOW_AUTOSIZE              = 1
  EVENT_MOUSEMOVE              = 0
  EVENT_LBUTTONDOWN            = 1
  EVENT_RBUTTONDOWN            = 2
  EVENT_MBUTTONDOWN            = 3
  EVENT_LBUTTONUP              = 4
  EVENT_RBUTTONUP              = 5
  EVENT_MBUTTONUP              = 6
  EVENT_LBUTTONDBLCLK          = 7
  EVENT_RBUTTONDBLCLK          = 8
  EVENT_MBUTTONDBLCLK          = 9
  EVENT_FLAG_LBUTTON           = 1
  EVENT_FLAG_RBUTTON           = 2
  EVENT_FLAG_MBUTTON           = 4
  EVENT_FLAG_CTRLKEY           = 8
  EVENT_FLAG_SHIFTKEY          = 16
  EVENT_FLAG_ALTKEY            = 32
  CAP_ANY                      = 0
  CAP_MIL                      = 100
  CAP_VFW                      = 200
  CAP_V4L                      = 200
  CAP_V4L2                     = 200
  CAP_FIREWARE                 = 300
  CAP_FIREWIRE                 = 300
  CAP_IEEE1394                 = 300
  CAP_DC1394                   = 300
  CAP_CMU1394                  = 300
  CAP_STEREO                   = 400
  CAP_TYZX                     = 400
  TYZX_LEFT                    = 400
  TYZX_RIGHT                   = 401
  TYZX_COLOR                   = 402
  TYZX_Z                       = 403
  CAP_QT                       = 500
  CAP_UNICAP                   = 600
  CAP_DSHOW                    = 700
  CAP_PROP_POS_MSEC            = 0
  CAP_PROP_POS_FRAMES          = 1
  CAP_PROP_POS_AVI_RATIO       = 2
  CAP_PROP_FRAME_WIDTH         = 3
  CAP_PROP_FRAME_HEIGHT        = 4
  CAP_PROP_FPS                 = 5
  CAP_PROP_FOURCC              = 6
  CAP_PROP_FRAME_COUNT         = 7
  CAP_PROP_FORMAT              = 8
  CAP_PROP_MODE                = 9
  CAP_PROP_BRIGHTNESS          = 10
  CAP_PROP_CONTRAST            = 11
  CAP_PROP_SATURATION          = 12
  CAP_PROP_HUE                 = 13
  CAP_PROP_GAIN                = 14
  CAP_PROP_EXPOSURE            = 15
  CAP_PROP_CONVERT_RGB         = 16
  CAP_PROP_WHITE_BALANCE       = 17
  CAP_PROP_RECTIFICATION       = 18
  COL_SAMPLE                   = 0
  ROW_SAMPLE                   = 1
  VAR_NUMERICAL                = 0
  VAR_ORDERED                  = 0
  VAR_CATEGORICAL              = 1
  TRAIN_ERROR                  = 0
  TEST_ERROR                   = 1
  CNN_LEARN_RATE_DECREASE_HYPERBOLICALLY= 1
  CNN_LEARN_RATE_DECREASE_SQRT_INV= 2
  CNN_LEARN_RATE_DECREASE_LOG_INV= 3
  CNN_GRAD_ESTIM_RANDOM        = 0
  CNN_GRAD_ESTIM_BY_WORST_IMG  = 1
  ICNN_LAYER                   = 0x55550000
  ICNN_CONVOLUTION_LAYER       = 0x00001111
  ICNN_SUBSAMPLING_LAYER       = 0x00002222
  ICNN_FULLCONNECT_LAYER       = 0x00003333
  TS_CONCENTRIC_SPHERES        = 0
  COUNT                        = 0
  PORTION                      = 1
)


type Block func(...) (result interface{})


type Image struct { 
  cimage * C.IplImage
}

type mystring string;

const debug_ok = true

// debug prints a debug message on stdout if the contant debug_ok is true 
func debug(message string) {
  if debug_ok {
    fmt.Fprintln(os.Stderr, message) 
  }
}

// free is a method on C char * strings to method to free the associated memory 
func (self * C.char) free() {
  C.free(unsafe.Pointer(self))
}

// cstring converts a string th a C string. This alloactes memory, so don't 
// forget a defer s.free 
func cstr(self string) (* C.char) {
  return C.CString(self)
}

func (self mystring) cstr() (* C.char) {
  return C.CString(string(self))
}

// SetErrStatus sets the error status.
// The function sets the error status to the specified value. 
// Mostly, the function is used to reset the error status (set to it StsOk) 
// to recover after an error. In other cases it is more natural to call Error.
func SetErrStatus(status int) {
  C.cvSetErrStatus(C.int(status))
}


// constants for SetErrMode
const (
  /* Print error and exit program */
  ErrModeLeaf     =  0   
  /* Print error and continue */
  ErrModeParent   =  1   
  /* Don't print and continue */
  ErrModeSilent   =  2   
)

// SetErrMode sets the specified error mode. For descriptions of different 
// error modes, see the beginning of the error section.
func SetErrMode(mode int) {
  C.cvSetErrMode(C.int(mode))
}


// GetErrStatus returns the current error status.
// The function returns the current error status - the value set with the last 
// SetErrStatus call. Note that in Leaf mode, the program terminates immediately 
// after an error occurs, so to always gain control after the function call, 
// one should call SetErrMode and set the Parent or Silent error mode.
func GetErrStatus() int {
  return int(C.cvGetErrStatus());
}

// GetErrMode returns the current error mode.
// The function returns the current error mode - the value set with the last 
// SetErrMode call.
func GetErrMode() int {
  return int(C.cvGetErrMode());
}

// Error raises an error.
// Parameters: 
//        * status – The error status
//        * func_name – Name of the function where the error occured
//        * err_msg – Additional information/diagnostics about the error
//        * filename – Name of the file where the error occured
//        * line – Line number, where the error occured
// The function sets the error status to the specified value (via SetErrStatus) 
// and, if the error mode is not Silent, calls the error handler.

func Error(status int, func_name, err_msg, filename string, line int) {
  cfunc   := cstr(func_name)  ; defer cfunc.free()
  cerr    := cstr(err_msg)    ; defer cerr.free()
  cfile   := cstr(filename)   ; defer cfile.free()
  cstatus := C.int(status)
  cline   := C.int(line)
  C.cvError(cstatus, cfunc, cerr, cfile, cline)
}

//ErrorStr returns textual description of an error status code.
//Parameter:  status – The error status

//The function returns the textual description for the specified error status 
// code. In the case of unknown status, the function returns a NULL pointer.
func ErrorStr(status int) string {
  cstr    := C.cvErrorStr(C.int(status))
  return C.GoString(cstr)
}

// RedirectError and other error callbacks not supported 



// Initializes opencv, particularily it's error handling
func init() {
  debug("Opencv Init OK")
  SetErrMode(ErrModeParent)
}


/*
func (Image self) destroy() {
  C.IplImageFree(self)
}
*/

func WrapImage(cimage * C.IplImage) * Image {
  if cimage == nil {
    return nil
  }
  return &Image{cimage}
} 

// Constants for LoadImage
const (
  LOAD_IMAGE_GRAYSCALE         = 0
  LOAD_IMAGE_COLOR             = 1
  LOAD_IMAGE_ANYDEPTH          = 2
  LOAD_IMAGE_ANYCOLOR          = 4
)  

// Loadimage loads an image 
func LoadImage(filename string, iscolor int) * Image {
  cfile   := C.CString(filename)
  defer   cfile.free()
  ccolor  := C.int(iscolor)  
  cimage  := C.cvLoadImage(cfile, ccolor)
  
  if cimage == nil {
    return nil
  }
  return WrapImage(cimage)
}

func (self *C.IplImage) releaseimage() {
  C.cvReleaseImage(&self)
}

//Constantd declarations for SaveEX
const (
  IMWRITE_JPEG_QUALITY      = 1
  IMWRITE_PNG_COMPRESSION   = 16
  CV_IMWRITE_PXM_BINARY     = 32
)

//SaveEx saves the image to the named file name, with extra quality parameters.
//Returns true on success or false on failiure.
func (self * Image) SaveEx(filename string, quality int) (* Image) {
  cfile   := C.CString(filename)
  defer   cfile.free()
  if self.cimage == nil { return nil }
  cimage  := unsafe.Pointer(self.cimage)
  params  := make([]int, 1)
  params[0]= quality
  cparams := unsafe.Pointer(&params[0])
  res     := C.cvSaveImage(cfile, cimage, (*C.int)(cparams))
  if int(res) > 0  {  return self }
  return nil; 
}  

//Save saves the image to the named file name. 
//Returns true on success or false on failiure.
func (self * Image) Save(filename string) (* Image) {
  return self.SaveEx(filename, 0)
}
  
  

// Release releases the memory associated with the block
func (self * Image) Release() {
  if self.cimage != nil {
    self.cimage.releaseimage()
  }  
  self.cimage = nil
}

// Destructor for GC. Doesn't work yet.
func (self * Image) destroy() {
  self.Release()
  fmt.Println("Released!")
}

// Constants for image.Convert
const (
  CVTIMG_FLIP 		= 1
  CVTIMG_SWAP_RB 	= 2
)

// Concert converts one image to another with an optional vertical flip.
func (self * Image) Convert(destination * Image, flags int) {
  C.cvConvertImage(unsafe.Pointer(self.cimage), unsafe.Pointer(destination.cimage), C.int(flags))  
} 


// DestroyAllWindows() destroys all of the opened HighGUI windows.
func DestroyAllWindows() {
  C.cvDestroyAllWindows()
}


type Window struct {
  name string
}

// Destroy destroys a window.
func (self * Window) Destroy() {
  cname := cstr(self.name) ; defer cname.free()
  C.cvDestroyWindow(cname)
}


// Trackbar, a scroll bar inside a window
type Trackbar struct {
  handle int;
  value int;
  name string;
  window Window; 
}  

// CreateTrackbar method creates a trackbar and attaches it to the self window.
// Does not support callbacks yet.
func (self Window) CreateTrackbar(name string, value int, max int) * Trackbar {
  cname   := cstr(name)         ; defer cname.free()
  cwindow := cstr(self.name)  ; defer cwindow.free()
  cmax          := C.int(max)
  trackbar      := &Trackbar{0, value, name, self}
  cvalue        := (* C.int)(unsafe.Pointer(&trackbar.value))
  chandle       := C.cvCreateTrackbar(cname, cwindow, cvalue, cmax, nil)
  trackbar.handle = int(chandle)
  return trackbar
}

// Position returns the current position of the specified trackbar.
func (self * Trackbar) Position() int  {
  cname   := cstr(self.name)         ; defer cname.free()
  cwindow := cstr(self.window.name)  ; defer cwindow.free()
  cpos    := C.cvGetTrackbarPos(cname, cwindow)
  return int(cpos)
}

// SetPosition() sets the position of the specified trackbar.
func (self * Trackbar) SetPosition(pos int)  {
  cname   := cstr(self.name)         ; defer cname.free()
  cwindow := cstr(self.window.name)  ; defer cwindow.free()
  cpos    := C.int(pos) 
  C.cvSetTrackbarPos(cname, cwindow, cpos)
}

// cvGetWindowHandle not supported, since not needed
// cvGetWindowName(void* windowHandle) not supported since not needed (I hope)
// argc int argv[] string not supported yet
// Initializes HighGUI.
func InitSystem() {
  C.cvInitSystem(0, nil)
}

//Move sets the position of the window. 
func (self * Window) Move (x int, y int) {
  cwindow := cstr(self.name) ; defer cwindow.free()
  cx := C.int(x) ; cy := C.int(y)
  C.cvMoveWindow(cwindow, cx, cy)
}

//Resize resizes the window. 
func (self * Window) resize (w int, h int) {
  cwindow := cstr(self.name) ; defer cwindow.free()
  cw := C.int(w) ; ch := C.int(h)
  C.cvResizeWindow(cwindow, cw, ch)
}


// NewWindow creates a window with the given name and autosizing.
func NewWindow(name string, autosize bool) (*Window) {
  flags  := 0
  cname  := cstr(name) ; defer cname.free()  
  if autosize {  flags  =  WINDOW_AUTOSIZE }  
  cflags := C.int(flags)
  window := &Window{name: name}
  C.cvNamedWindow(cname, cflags)
  return window
} 

// Displays the image in the specified window
func (self * Window) ShowImage(image Image) { 
  cname  := cstr(self.name) ; defer cname.free()
  cimage := image.cimage
  C.cvShowImage(cname, unsafe.Pointer(cimage))
}

// Waits for a pressed key waits for key event infinitely delay <= 0 or for 
// delay milliseconds. Returns the code of the pressed key or -1 if no key was 
// pressed before the specified time had elapsed.
func WaitKey(delay int) int {
  cdelay  := C.int(delay)  
  ckey    := C.cvWaitKey(cdelay)
  return int(ckey)
}


/*
SetMouseCallback
void cvSetMouseCallback(const char* windowName, CvMouseCallback onMouse, void* param=NULL)
not supported yet
*/


/*
void cvAdaptiveThreshold(const CvArr* src, CvArr* dst, double maxValue, int adaptive_method=CV_ADAPTIVE_THRESH_MEAN_C, int thresholdType=CV_THRESH_BINARY, int blockSize=3, double param1=5)¶

    Applies an adaptive threshold to an array.
    Parameters: 

        * src – Source image
        * dst – Destination image
        * maxValue – Maximum value that is used with CV_THRESH_BINARY and CV_THRESH_BINARY_INV
        * adaptive_method – Adaptive thresholding algorithm to use: CV_ADAPTIVE_THRESH_MEAN_C or CV_ADAPTIVE_THRESH_GAUSSIAN_C (see the discussion)
        * thresholdType –

          Thresholding type; must be one of
              o CV_THRESH_BINARY - xxx
              o CV_THRESH_BINARY_INV - xxx
        * blockSize – The size of a pixel neighborhood that is used to calculate a threshold value for the pixel: 3, 5, 7, and so on
        * param1 – The method-dependent parameter. For the methods CV_ADAPTIVE_THRESH_MEAN_C and CV_ADAPTIVE_THRESH_GAUSSIAN_C it is a constant subtracted from the mean or weighted mean (see the discussion), though it may be negative

    The function transforms a grayscale image to a binary image according to the formulas:

            *

              CV_THRESH_BINARY -

              dst(x,y) = \fork {\texttt{maxValue}}{if $src(x,y) > T(x,y)$}{0}{otherwise}
            *

              CV_THRESH_BINARY_INV -

              dst(x,y) = \fork {0}{if $src(x,y) > T(x,y)$}{\texttt{maxValue}}{otherwise}

    where $T(x,y)$ is a threshold calculated individually for each pixel.

    For the method CV_ADAPTIVE_THRESH_MEAN_C it is the mean of a $\texttt{blockSize} \times \texttt{blockSize}$ pixel neighborhood, minus param1.

    For the method CV_ADAPTIVE_THRESH_GAUSSIAN_C it is the weighted sum (gaussian) of a $\texttt{blockSize} \times \texttt{blockSize}$ pixel neighborhood, minus param1.

CvtColor¶

void cvCvtColor(const CvArr* src, CvArr* dst, int code)¶

    Converts an image from one color space to another.
    Parameters: 

        * src – The source 8-bit (8u), 16-bit (16u) or single-precision floating-point (32f) image
        * dst – The destination image of the same data type as the source. The number of channels may be different
        * code – Color conversion operation that can be specifed using CV_ *src_color_space* 2 *dst_color_space* constants (see below)

    The function converts the input image from one color space to another. The function ignores the colorModel and channelSeq fields of the IplImage header, so the source image color space should be specified correctly (including order of the channels in the case of RGB space. For example, BGR means 24-bit format with $B_0, G_0, R_0, B_1, G_1, R_1, ...$ layout whereas RGB means 24-format with $R_0, G_0, B_0, R_1, G_1, B_1, ...$ layout).

    The conventional range for R,G,B channel values is:

        * 0 to 255 for 8-bit images
        * 0 to 65535 for 16-bit images and
        * 0 to 1 for floating-point images.

    Of course, in the case of linear transformations the range can be specific, but in order to get correct results in the case of non-linear transformations, the input image should be scaled.

    The function can do the following transformations:

        * Transformations within RGB space like adding/removing the alpha channel, reversing the channel order, conversion to/from 16-bit RGB color (R5:G6:B5 or R5:G5:B5), as well as conversion to/from grayscale using:

    \text {RGB[A] to Gray:} Y \leftarrow 0.299 \cdot R + 0.587 \cdot G + 0.114 \cdot B

    and

    \text {Gray to RGB[A]:} R \leftarrow Y, G \leftarrow Y, B \leftarrow Y, A \leftarrow 0

    The conversion from a RGB image to gray is done with:

        cvCvtColor(src ,bwsrc, CV_RGB2GRAY)

        * RGB $\leftrightarrow $ CIE XYZ.Rec 709 with D65 white point (CV_BGR2XYZ, CV_RGB2XYZ, CV_XYZ2BGR, CV_XYZ2RGB):

    \begin{bmatrix} X \\ Y \\ Z \end{bmatrix} \leftarrow \begin{bmatrix} 0.412453 & 0.357580 & 0.180423 \\ 0.212671 & 0.715160 & 0.072169 \\ 0.019334 & 0.119193 & 0.950227 \end{bmatrix} \cdot \begin{bmatrix} R \\ G \\ B \end{bmatrix}

    \begin{bmatrix} R \\ G \\ B \end{bmatrix} \leftarrow \begin{bmatrix} 3.240479 & -1.53715 & -0.498535 \\ -0.969256 & 1.875991 & 0.041556 \\ 0.055648 & -0.204043 & 1.057311 \end{bmatrix} \cdot \begin{bmatrix} X \\ Y \\ Z \end{bmatrix}

    $X$, $Y$ and $Z$ cover the whole value range (in the case of floating-point images $Z$ may exceed 1).

        * RGB $\leftrightarrow $ YCrCb JPEG (a.k.a. YCC) (CV_BGR2YCrCb, CV_RGB2YCrCb, CV_YCrCb2BGR, CV_YCrCb2RGB)

    Y \leftarrow 0.299 \cdot R + 0.587 \cdot G + 0.114 \cdot B

    Cr \leftarrow (R-Y) \cdot 0.713 + delta

    Cb \leftarrow (B-Y) \cdot 0.564 + delta

    R \leftarrow Y + 1.403 \cdot (Cr - delta)

    G \leftarrow Y - 0.344 \cdot (Cr - delta) - 0.714 \cdot (Cb - delta)

    B \leftarrow Y + 1.773 \cdot (Cb - delta)

    where

    delta = \left\{ \begin{array}{l l} 128 & \mbox{for 8-bit images}\\ 32768 & \mbox{for 16-bit images}\\ 0.5 & \mbox{for floating-point images} \end{array} \right.

    Y, Cr and Cb cover the whole value range.

        * RGB $\leftrightarrow $ HSV (CV_BGR2HSV, CV_RGB2HSV, CV_HSV2BGR, CV_HSV2RGB) in the case of 8-bit and 16-bit images R, G and B are converted to floating-point format and scaled to fit the 0 to 1 range

    V \leftarrow max(R,G,B)

    S \leftarrow \fork {\frac{V-min(R,G,B)}{V}}{if $V \neq 0$}{0}{otherwise}

    H \leftarrow \forkthree {{60(G - B)}/{S}}{if $V=R$} {{120+60(B - R)}/{S}}{if $V=G$} {{240+60(R - G)}/{S}}{if $V=B$}

    if $H<0$ then $H \leftarrow H+360$

    On output $0 \leq V \leq 1$, $0 \leq S \leq 1$, $0 \leq H \leq 360$.

    The values are then converted to the destination data type:

        *

          8-bit images *

              V \leftarrow 255 V, S \leftarrow 255 S, H \leftarrow H/2 \text {(to fit to 0 to 255)}

        *

          16-bit images (currently not supported) *

              V <- 65535 V, S <- 65535 S, H <- H

        *

          32-bit images *

              H, S, V are left as is

        *

          RGB $\leftrightarrow $ HLS (CV_BGR2HLS, CV_RGB2HLS, CV_HLS2BGR, CV_HLS2RGB). in the case of 8-bit and 16-bit images R, G and B are converted to floating-point format and scaled to fit the 0 to 1 range.

    V_{max} \leftarrow {max}(R,G,B)

    V_{min} \leftarrow {min}(R,G,B)

    L \leftarrow \frac{V_{max} - V_{min}}{2}

    S \leftarrow \fork {\frac{V_{max} - V_{min}}{V_{max} + V_{min}}}{if $L < 0.5$} {\frac{V_{max} - V_{min}}{2 - (V_{max} + V_{min})}}{if $L \ge 0.5$}

    H \leftarrow \forkthree {{60(G - B)}/{S}}{if $V_{max}=R$} {{120+60(B - R)}/{S}}{if $V_{max}=G$} {{240+60(R - G)}/{S}}{if $V_{max}=B$}

    if $H<0$ then $H \leftarrow H+360$ On output $0 \leq V \leq 1$, $0 \leq S \leq 1$, $0 \leq H \leq 360$.

    The values are then converted to the destination data type:

        *

          8-bit images *

              V \leftarrow 255 V, S \leftarrow 255 S, H \leftarrow H/2 \text {(to fit to 0 to 255)}

        *

          16-bit images (currently not supported) *

              V <- 65535 V, S <- 65535 S, H <- H

        *

          32-bit images *

              H, S, V are left as is

        *

          RGB $\leftrightarrow $ CIE L*a*b* (CV_BGR2Lab, CV_RGB2Lab, CV_Lab2BGR, CV_Lab2RGB) in the case of 8-bit and 16-bit images R, G and B are converted to floating-point format and scaled to fit the 0 to 1 range

    \vecthree {X}{Y}{Z} \leftarrow \vecthreethree {0.412453}{0.357580}{0.180423} {0.212671}{0.715160}{0.072169} {0.019334}{0.119193}{0.950227} \cdot \vecthree {R}{G}{B}

    X \leftarrow X/X_ n, \text {where} X_ n = 0.950456

    Z \leftarrow Z/Z_ n, \text {where} Z_ n = 1.088754

    L \leftarrow \fork {116*Y^{1/3}-16}{for $Y>0.008856$} {903.3*Y}{for $Y \le 0.008856$}

    a \leftarrow 500 (f(X)-f(Y)) + delta

    b \leftarrow 200 (f(Y)-f(Z)) + delta

    where

    f(t)=\fork {t^{1/3}}{for $t>0.008856$} {7.787 t+16/116}{for $t<=0.008856$}

    and

    delta = \fork {128}{for 8-bit images}{0}{for floating-point images}

    On output $0 \leq L \leq 100$, $-127 \leq a \leq 127$, $-127 \leq b \leq 127$

    The values are then converted to the destination data type:

        *

          8-bit images *

              L \leftarrow L*255/100, a \leftarrow a + 128, b \leftarrow b + 128

        *

          16-bit images *

              currently not supported

        *

          32-bit images *

              L, a, b are left as is

        *

          RGB $\leftrightarrow $ CIE L*u*v* (CV_BGR2Luv, CV_RGB2Luv, CV_Luv2BGR, CV_Luv2RGB) in the case of 8-bit and 16-bit images R, G and B are converted to floating-point format and scaled to fit 0 to 1 range

    \vecthree {X}{Y}{Z} \leftarrow \vecthreethree {0.412453}{0.357580}{0.180423} {0.212671}{0.715160}{0.072169} {0.019334}{0.119193}{0.950227} \cdot \vecthree {R}{G}{B}

    L \leftarrow \fork {116 Y^{1/3}}{for $Y>0.008856$} {903.3 Y}{for $Y<=0.008856$}

    u' \leftarrow 4*X/(X + 15*Y + 3 Z)

    v' \leftarrow 9*Y/(X + 15*Y + 3 Z)

    u \leftarrow 13*L*(u' - u_ n) \quad \text {where} \quad u_ n=0.19793943

    v \leftarrow 13*L*(v' - v_ n) \quad \text {where} \quad v_ n=0.46831096

    On output $0 \leq L \leq 100$, $-134 \leq u \leq 220$, $-140 \leq v \leq 122$.

    The values are then converted to the destination data type:

        *

          8-bit images *

              L \leftarrow 255/100 L, u \leftarrow 255/354 (u + 134), v \leftarrow 255/256 (v + 140)

        *

          16-bit images *

              currently not supported

        *

          32-bit images *

              L, u, v are left as is

    The above formulas for converting RGB to/from various color spaces have been taken from multiple sources on Web, primarily from the Ford98 at the Charles Poynton site.

        * Bayer $\rightarrow $ RGB (CV_BayerBG2BGR, CV_BayerGB2BGR, CV_BayerRG2BGR, CV_BayerGR2BGR, CV_BayerBG2RGB, CV_BayerGB2RGB, CV_BayerRG2RGB, CV_BayerGR2RGB) The Bayer pattern is widely used in CCD and CMOS cameras. It allows one to get color pictures from a single plane where R,G and B pixels (sensors of a particular component) are interleaved like this:

    \definecolor {BackGray}{rgb}{0.8,0.8,0.8} \begin{array}{ c c c c c } \color {red}R& \color {green}G& \color {red}R& \color {green}G& \color {red}R\\ \color {green}G& \colorbox {BackGray}{\color {blue}B}& \colorbox {BackGray}{\color {green}G}& \color {blue}B& \color {green}G\\ \color {red}R& \color {green}G& \color {red}R& \color {green}G& \color {red}R\\ \color {green}G& \color {blue}B& \color {green}G& \color {blue}B& \color {green}G\\ \color {red}R& \color {green}G& \color {red}R& \color {green}G& \color {red}R\end{array}

    The output RGB components of a pixel are interpolated from 1, 2 or 4 neighbors of the pixel having the same color. There are several modifications of the above pattern that can be achieved by shifting the pattern one pixel left and/or one pixel up. The two letters $C_1$ and $C_2$ in the conversion constants CV_Bayer $ C_1 C_2 $ 2BGR and CV_Bayer $ C_1 C_2 $ 2RGB indicate the particular pattern type - these are components from the second row, second and third columns, respectively. For example, the above pattern has very popular “BG” type.

DistTransform¶

void cvDistTransform(const CvArr* src, CvArr* dst, int distance_type=CV_DIST_L2, int mask_size=3, const float* mask=NULL, CvArr* labels=NULL)¶

    Calculates the distance to the closest zero pixel for all non-zero pixels of the source image.
    Parameters: 

        * src – 8-bit, single-channel (binary) source image
        * dst – Output image with calculated distances (32-bit floating-point, single-channel)
        * distance_type – Type of distance; can be CV_DIST_L1, CV_DIST_L2, CV_DIST_C or CV_DIST_USER
        * mask_size – Size of the distance transform mask; can be 3 or 5. in the case of CV_DIST_L1 or CV_DIST_C the parameter is forced to 3, because a $3\times 3$ mask gives the same result as a $5\times 5 $ yet it is faster
        * mask – User-defined mask in the case of a user-defined distance, it consists of 2 numbers (horizontal/vertical shift cost, diagonal shift cost) in the case ofa $3\times 3$ mask and 3 numbers (horizontal/vertical shift cost, diagonal shift cost, knight’s move cost) in the case of a $5\times 5$ mask
        * labels – The optional output 2d array of integer type labels, the same size as src and dst

    The function calculates the approximated distance from every binary image pixel to the nearest zero pixel. For zero pixels the function sets the zero distance, for others it finds the shortest path consisting of basic shifts: horizontal, vertical, diagonal or knight’s move (the latest is available for a $5\times 5$ mask). The overall distance is calculated as a sum of these basic distances. Because the distance function should be symmetric, all of the horizontal and vertical shifts must have the same cost (that is denoted as a), all the diagonal shifts must have the same cost (denoted b), and all knight’s moves must have the same cost (denoted c). For CV_DIST_C and CV_DIST_L1 types the distance is calculated precisely, whereas for CV_DIST_L2 (Euclidian distance) the distance can be calculated only with some relative error (a $5\times 5$ mask gives more accurate results), OpenCV uses the values suggested in :
    CV_DIST_C   $(3\times 3)$   a = 1, b = 1
    CV_DIST_L1  $(3\times 3)$   a = 1, b = 2
    CV_DIST_L2  $(3\times 3)$   a=0.955, b=1.3693
    CV_DIST_L2  $(5\times 5)$   a=1, b=1.4, c=2.1969

    And below are samples of the distance field (black (0) pixel is in the middle of white square) in the case of a user-defined distance:

    User-defined $3 \times 3$ mask (a=1, b=1.5)
    4.5   4   3.5   3   3.5   4   4.5
    4   3   2.5   2   2.5   3   4
    3.5   2.5   1.5   1   1.5   2.5   3.5
    3   2   1       1   2   3
    3.5   2.5   1.5   1   1.5   2.5   3.5
    4   3   2.5   2   2.5   3   4
    4.5   4   3.5   3   3.5   4   4.5

    User-defined $5 \times 5$ mask (a=1, b=1.5, c=2)
    4.5   3.5   3   3   3   3.5   4.5
    3.5   3   2   2   2   3   3.5
    3   2   1.5   1   1.5   2   3
    3   2   1       1   2   3
    3   2   1.5   1   1.5   2   3
    3.5   3   2   2   2   3   3.5
    4   3.5   3   3   3   3.5   4

    Typically, for a fast, coarse distance estimation CV_DIST_L2, a $3\times 3$ mask is used, and for a more accurate distance estimation CV_DIST_L2, a $5\times 5$ mask is used.

    When the output parameter labels is not NULL, for every non-zero pixel the function also finds the nearest connected component consisting of zero pixels. The connected components themselves are found as contours in the beginning of the function.

    In this mode the processing time is still O(N), where N is the number of pixels. Thus, the function provides a very fast way to compute approximate Voronoi diagram for the binary image.

FloodFill¶

void cvFloodFill(CvArr* image, CvPoint seed_point, CvScalar new_val, CvScalar lo_diff=cvScalarAll(0), CvScalar up_diff=cvScalarAll(0), CvConnectedComp* comp=NULL, int flags=4, CvArr* mask=NULL)¶

    Fills a connected component with the given color.

        typedef struct CvConnectedComp
        {
            double area;     area of the segmented component
            CvScalar value;  average color of the connected component 
            CvRect rect;     ROI of the segmented component 
            CvSeq* contour;  optional component boundary
                              (the contour might have child contours corresponding to the holes) 
        } CvConnectedComp;

        #define CV_FLOODFILL_FIXED_RANGE (1 << 16)
        #define CV_FLOODFILL_MASK_ONLY   (1 << 17)

    Parameters: 

        * image – Input 1- or 3-channel, 8-bit or floating-point image. It is modified by the function unless the CV_FLOODFILL_MASK_ONLY flag is set (see below)
        * seed_point – The starting point
        * new_val – New value of the repainted domain pixels
        * lo_diff – Maximal lower brightness/color difference between the currently observed pixel and one of its neighbors belonging to the component, or a seed pixel being added to the component. In the case of 8-bit color images it is a packed value
        * up_diff – Maximal upper brightness/color difference between the currently observed pixel and one of its neighbors belonging to the component, or a seed pixel being added to the component. In the case of 8-bit color images it is a packed value
        * comp – Pointer to the structure that the function fills with the information about the repainted domain
        * flags –

          The operation flags. Lower bits contain connectivity value, 4 (by default) or 8, used within the function. Connectivity determines which neighbors of a pixel are considered. Upper bits can be 0 or a combination of the following flags:
              o CV_FLOODFILL_FIXED_RANGE - if set, the difference between the current pixel and seed pixel is considered, otherwise the difference between neighbor pixels is considered (the range is floating)
              o CV_FLOODFILL_MASK_ONLY - if set, the function does not fill the image (new_val is ignored), but fills the mask (that must be non-NULL in this case)
        * mask – Operation mask, should be a single-channel 8-bit image, 2 pixels wider and 2 pixels taller than image. If not NULL, the function uses and updates the mask, so the user takes responsibility of initializing the mask content. Floodfilling can’t go across non-zero pixels in the mask, for example, an edge detector output can be used as a mask to stop filling at edges. It is possible to use the same mask in multiple calls to the function to make sure the filled area do not overlap. Note: because the mask is larger than the filled image, a pixel in mask that corresponds to $(x,y)$ pixel in image will have coordinates $(x+1,y+1)$

    The function fills a connected component starting from the seed point with the specified color. The connectivity is determined by the closeness of pixel values. The pixel at $(x,y)$ is considered to belong to the repainted domain if:

        *

          grayscale image, floating range *

              src(x',y')-\texttt{lo\_ diff} <= src(x,y) <= src(x',y')+\texttt{up\_ diff}

        *

          grayscale image, fixed range *

              src(seed.x,seed.y)-\texttt{lo\_ diff}<=src(x,y)<=src(seed.x,seed.y)+\texttt{up\_ diff}

        *

          color image, floating range *

              src(x',y')_ r-\texttt{lo\_ diff}_ r<=src(x,y)_ r<=src(x',y')_ r+\texttt{up\_ diff}_ r

              src(x',y')_ g-\texttt{lo\_ diff}_ g<=src(x,y)_ g<=src(x',y')_ g+\texttt{up\_ diff}_ g

              src(x',y')_ b-\texttt{lo\_ diff}_ b<=src(x,y)_ b<=src(x',y')_ b+\texttt{up\_ diff}_ b

        *

          color image, fixed range *

              src(seed.x,seed.y)_ r-\texttt{lo\_ diff}_ r<=src(x,y)_ r<=src(seed.x,seed.y)_ r+\texttt{up\_ diff}_ r

              src(seed.x,seed.y)_ g-\texttt{lo\_ diff}_ g<=src(x,y)_ g<=src(seed.x,seed.y)_ g+\texttt{up\_ diff}_ g

              src(seed.x,seed.y)_ b-\texttt{lo\_ diff}_ b<=src(x,y)_ b<=src(seed.x,seed.y)_ b+\texttt{up\_ diff}_ b

    where $src(x’,y’)$ is the value of one of pixel neighbors. That is, to be added to the connected component, a pixel’s color/brightness should be close enough to the:

        * color/brightness of one of its neighbors that are already referred to the connected component in the case of floating range
        * color/brightness of the seed point in the case of fixed range.

Inpaint¶

void cvInpaint(const CvArr* src, const CvArr* mask, CvArr* dst, double inpaintRadius, int flags)¶

    Inpaints the selected region in the image.
    Parameters: 

        * src – The input 8-bit 1-channel or 3-channel image.
        * mask – The inpainting mask, 8-bit 1-channel image. Non-zero pixels indicate the area that needs to be inpainted.
        * dst – The output image of the same format and the same size as input.
        * inpaintRadius – The radius of circlular neighborhood of each point inpainted that is considered by the algorithm.
        * flags –

          The inpainting method, one of the following:
              o CV_INPAINT_NS - Navier-Stokes based method.
              o CV_INPAINT_TELEA - The method by Alexandru Telea bgroup({# Telea04})bgroup({[Telea04]})

    The function reconstructs the selected image area from the pixel near the area boundary. The function may be used to remove dust and scratches from a scanned photo, or to remove undesirable objects from still images or video.

Integral¶

void cvIntegral(const CvArr* image, CvArr* sum, CvArr* sqsum=NULL, CvArr* tiltedSum=NULL)¶

    Calculates the integral of an image.
    Parameters: 

        * image – The source image, $W\times H$, 8-bit or floating-point (32f or 64f)
        * sum – The integral image, $(W+1)\times (H+1)$, 32-bit integer or double precision floating-point (64f)
        * sqsum – The integral image for squared pixel values, $(W+1)\times (H+1)$, double precision floating-point (64f)
        * tiltedSum – The integral for the image rotated by 45 degrees, $(W+1)\times (H+1)$, the same data type as sum

    The function calculates one or more integral images for the source image as following:

    \texttt{sum}(X,Y) = \sum _{x<X,y<Y} \texttt{image}(x,y)

    \texttt{sqsum}(X,Y) = \sum _{x<X,y<Y} \texttt{image}(x,y)^2

    \texttt{tiltedSum}(X,Y) = \sum _{y<Y,abs(x-X)<y} \texttt{image}(x,y)

    Using these integral images, one may calculate sum, mean and standard deviation over a specific up-right or rotated rectangular region of the image in a constant time, for example:

    \sum _{x_1<=x<x_2, \, y_1<=y<y_2} = \texttt{sum}(x_2,y_2)-\texttt{sum}(x_1,y_2)-\texttt{sum}(x_2,y_1)+\texttt{sum}(x_1,x_1)

    It makes possible to do a fast blurring or fast block correlation with variable window size, for example. In the case of multi-channel images, sums for each channel are accumulated independently.

PyrMeanShiftFiltering¶

void cvPyrMeanShiftFiltering(const CvArr* src, CvArr* dst, double sp, double sr, int max_level=1, CvTermCriteria termcrit=cvTermCriteria(CV_TERMCRIT_ITER+CV_TERMCRIT_EPS, 5, 1))¶

    Does meanshift image segmentation
    Parameters: 

        * src – The source 8-bit, 3-channel image.
        * dst – The destination image of the same format and the same size as the source.
        * sp – The spatial window radius.
        * sr – The color window radius.
        * max_level – Maximum level of the pyramid for the segmentation.
        * termcrit – Termination criteria: when to stop meanshift iterations.

    The function implements the filtering stage of meanshift segmentation, that is, the output of the function is the filtered “posterized” image with color gradients and fine-grain texture flattened. At every pixel $(X,Y)$ of the input image (or down-sized input image, see below) the function executes meanshift iterations, that is, the pixel $(X,Y)$ neighborhood in the joint space-color hyperspace is considered:

    (x,y): X-\texttt{sp} \le x \le X+\texttt{sp} , Y-\texttt{sp} \le y \le Y+\texttt{sp} , ||(R,G,B)-(r,g,b)|| \le \texttt{sr}

    where (R,G,B) and (r,g,b) are the vectors of color components at (X,Y) and (x,y), respectively (though, the algorithm does not depend on the color space used, so any 3-component color space can be used instead). Over the neighborhood the average spatial value (X',Y') and average color vector (R',G',B') are found and they act as the neighborhood center on the next iteration:

    $(X,Y)~ (X’,Y’), (R,G,B)~ (R’,G’,B’).$

    After the iterations over, the color components of the initial pixel (that is, the pixel from where the iterations started) are set to the final value (average color at the last iteration):

    $I(X,Y) <- (R*,G*,B*)$

    Then $\texttt{max\_ level}>0$ , the gaussian pyramid of $\texttt{max\_ level}+1$ levels is built, and the above procedure is run on the smallest layer. After that, the results are propagated to the larger layer and the iterations are run again only on those pixels where the layer colors differ much ( $>\texttt{sr}$ ) from the lower-resolution layer, that is, the boundaries of the color regions are clarified. Note, that the results will be actually different from the ones obtained by running the meanshift procedure on the whole original image (i.e. when $\texttt{max\_ level}==0$ ).

PyrSegmentation¶

void cvPyrSegmentation(IplImage* src, IplImage* dst, CvMemStorage* storage, CvSeq** comp, int level, double threshold1, double threshold2)¶

    Implements image segmentation by pyramids.
    Parameters: 

        * src – The source image
        * dst – The destination image
        * storage – Storage; stores the resulting sequence of connected components
        * comp – Pointer to the output sequence of the segmented components
        * level – Maximum level of the pyramid for the segmentation
        * threshold1 – Error threshold for establishing the links
        * threshold2 – Error threshold for the segments clustering

    The function implements image segmentation by pyramids. The pyramid builds up to the level level. The links between any pixel a on level i and its candidate father pixel b on the adjacent level are established if $p(c(a),c(b))<threshold1$. After the connected components are defined, they are joined into several clusters. Any two segments A and B belong to the same cluster, if $p(c(A),c(B))<threshold2$. If the input image has only one channel, then $p(c^1,c^2)=|c^1-c^2|$. If the input image has three channels (red, green and blue), then

    p(c^1,c^2) = 0.30 (c^1_ r - c^2_ r) + 0.59 (c^1_ g - c^2_ g) + 0.11 (c^1_ b - c^2_ b).

    There may be more than one connected component per a cluster. The images src and dst should be 8-bit single-channel or 3-channel images or equal size.

Threshold¶

double cvThreshold(const CvArr* src, CvArr* dst, double threshold, double maxValue, int thresholdType)¶
*/



/*
type Object struct {
  vtable Vtable;
}

type Method func (self * Object) (args ...) (* Object)
type Vtable map[string] Method;

func NewObject() (*Object) {
  ro  := Object{make(map[string] Method)}
  return &ro
}

func (self * Object) define_method(name string, method Method) (* Object) {
  self.vtable[name] = method
  return self
}

func (self * Object) send(message string, args...) (* Object) {
  method := self.vtable[message]
  result := (self).method(args)
  return result
}
 
type String struct { 
  * Object
  value string;
}
   
func NewString(s string) (* String)  {
  return &String{NewObject(), s}
}
   
func Hi(self * String, args...) ( * Object ) {
  // s := (String)(*self)
  debug("Hi")
  return self
}

type Vector struct {
  x int
  y int
} 

func VectorNew(x int, y int)  (* Vector) {
  return &Vector{x, y}
}
 
 
func (self * Vector) add (other * Vector) (* Vector)  {
  result := VectorNew(self.x + other.x, self.y + other.y) 
  return result 
}

func (self * Vector) X (other * Vector) (* Vector) {
  result := VectorNew(self.x * other.x, self.y * other.y)
  return result
}


var (
  v1 = VectorNew(10, 20)
  v2 = VectorNew(20, 30)
  vr = v1.add(v2)
  o1 = NewString("Hi!")
  o2 = o1.define_method("hi", Hi)
  o3 = o2.send("hi")
)
*/
